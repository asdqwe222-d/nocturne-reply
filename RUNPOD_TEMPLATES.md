# üéØ RunPod Templates & Exempel Repos

## Problem

Ollama-installation i Dockerfile orsakar problem. L√•t oss anv√§nda ett RunPod template eller exempel-repo ist√§llet!

## L√∂sning: Anv√§nd RunPod Ollama Template

RunPod har templates som redan har Ollama konfigurerat. Detta √§r mycket enklare!

---

## Option 1: RunPod Ollama Template (Rekommenderat)

### Steg 1: Skapa nytt Endpoint fr√•n Template

1. **G√• till RunPod Dashboard ‚Üí Serverless**
2. **Klicka "New Endpoint"**
3. **V√§lj "Templates" tab** (ist√§llet f√∂r "Import Git Repository")
4. **S√∂k efter "Ollama"**
5. **V√§lj "Ollama Serverless" eller liknande template**

### Steg 2: Konfigurera Template

**Basic Settings:**
- Endpoint Name: `nocturne-ollama`
- GPU Type: A40 eller RTX 3090
- Worker Type: Flex

**Template Settings:**
- Model: `nocturne-swe` (eller din modell)
- Environment Variables:
  ```
  OLLAMA_MODEL=nocturne-swe
  OLLAMA_HOST=0.0.0.0:11434
  ```

### Steg 3: Anpassa f√∂r din handler.py

Efter att endpoint √§r skapad:
- Du kan antingen:
  - **Option A:** Anv√§nd template som den √§r och anropa Ollama direkt
  - **Option B:** L√§gg till din handler.py via GitHub integration senare

---

## Option 2: Fork RunPod Ollama Exempel Repo

RunPod har f√∂rmodligen exempel-repos p√• GitHub:

1. **S√∂k p√• GitHub:**
   - `runpod/ollama-serverless`
   - `runpod/serverless-templates`
   - `runpod/ollama-example`

2. **Fork repo:**
   - Klicka "Fork" p√• GitHub
   - L√§gg till din handler.py
   - Push till ditt fork

3. **Anv√§nd i RunPod:**
   - Skapa endpoint fr√•n ditt fork
   - Konfigurera som vanligt

---

## Option 3: Anv√§nd RunPod Ollama Base Image

Ist√§llet f√∂r att installera Ollama sj√§lv, anv√§nd RunPods Ollama base image:

```dockerfile
FROM runpod/ollama:latest

WORKDIR /app
COPY handler.py /app/handler.py
COPY requirements.txt /app/requirements.txt

RUN pip install --no-cache-dir runpod requests

ENV OLLAMA_MODEL=nocturne-swe
ENV OLLAMA_HOST=0.0.0.0:11434

CMD ["python", "/app/handler.py"]
```

**Kolla om `runpod/ollama:latest` finns:**
- RunPod kan ha en officiell Ollama image
- Eller anv√§nd `ollama/ollama:latest` fr√•n Docker Hub

---

## Option 4: Anv√§nd Ollama Docker Image direkt

```dockerfile
FROM ollama/ollama:latest

# Install Python och dependencies
RUN apt-get update && apt-get install -y python3 python3-pip && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY handler.py /app/handler.py
COPY requirements.txt /app/requirements.txt

RUN pip3 install --no-cache-dir runpod requests

ENV OLLAMA_MODEL=nocturne-swe
ENV OLLAMA_HOST=0.0.0.0:11434

CMD ["python3", "/app/handler.py"]
```

---

## Rekommendation

**B√∂rja med Option 1 (RunPod Template)** - det √§r enklast och mest testat!

Om template inte finns eller inte fungerar:
- Prova Option 4 (Ollama Docker image direkt)
- Eller Option 3 (RunPod Ollama base image om den finns)

---

**Vilken option vill du prova f√∂rst?** üöÄ

