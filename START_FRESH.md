# ðŸš€ Starta Om - Enkel Guide frÃ¥n BÃ¶rjan

## MÃ¥l

KÃ¶ra din anpassade `nocturne-swe` modell pÃ¥ RunPod Serverless.

---

## Steg 1: Verifiera Din Kod Lokalt

### 1.1 Kontrollera Filer

Se till att du har dessa filer i `gpt-relay-server/`:

```
gpt-relay-server/
â”œâ”€â”€ handler.py          âœ… (skapar modellen automatiskt)
â”œâ”€â”€ Dockerfile          âœ… (inkluderar Modelfile)
â”œâ”€â”€ Modelfile           âœ… (din anpassade modell)
â”œâ”€â”€ requirements.txt    âœ…
â””â”€â”€ .runpod/
    â””â”€â”€ hub.json       âœ…
```

### 1.2 Testa Lokalt FÃ¶rst

```bash
cd gpt-relay-server
node server.js
```

Testa frÃ¥n `http://localhost:3000/test-chat.html` med lokal Ollama.

**Om detta fungerar lokalt:** FortsÃ¤tt till Steg 2.
**Om detta inte fungerar:** Fixa lokalt fÃ¶rst.

---

## Steg 2: Pusha Allt till GitHub

### 2.1 Kontrollera Git Status

```bash
cd gpt-relay-server
git status
```

### 2.2 LÃ¤gg Till Alla Filer

```bash
git add .
git commit -m "Ready for RunPod deployment"
git push
```

### 2.3 Verifiera pÃ¥ GitHub

GÃ¥ till: https://github.com/asdqwe222-d/nocturne-reply

Kontrollera att du ser:
- âœ… `handler.py`
- âœ… `Dockerfile`
- âœ… `Modelfile`
- âœ… `requirements.txt`

---

## Steg 3: Skapa RunPod Endpoint frÃ¥n GitHub

### 3.1 GÃ¥ till RunPod Dashboard

1. **GÃ¥ till:** https://console.runpod.io/serverless
2. **Klicka:** "New Endpoint"

### 3.2 VÃ¤lj "Import Git Repository"

**VIKTIGT:** VÃ¤lj **"Import Git Repository"** tab, INTE "Templates"!

### 3.3 Konfigurera Repository

- **Repository:** `asdqwe222-d/nocturne-reply`
- **Branch:** `main`

### 3.4 Docker Configuration

**Container Start Command:**
```
sh -c "ollama serve & sleep 5 && python /app/handler.py"
```

**Container Disk:** `20 GB` (modellen behÃ¶ver plats)

**Expose HTTP Ports:** `11434`

### 3.5 Environment Variables

LÃ¤gg till:
```
OLLAMA_MODEL=nocturne-swe
OLLAMA_HOST=0.0.0.0:11434
```

### 3.6 GPU & Workers

- **GPU Type:** RTX 3090 eller A40 (24GB+)
- **Max Workers:** 2
- **Active Workers:** 0 (fÃ¶r test)
- **Idle Timeout:** 5 sek

### 3.7 Skapa Endpoint

Klicka **"Create Endpoint"** eller **"Deploy"**

---

## Steg 4: VÃ¤nta pÃ¥ Build

### 4.1 Build Process

RunPod kommer:
1. âœ… Klona din GitHub repo
2. âœ… Bygga Docker image frÃ¥n Dockerfile
3. âœ… Starta containern

**Detta tar 2-5 minuter.**

### 4.2 FÃ¶rsta KÃ¶rning (NÃ¤r Worker Startar)

NÃ¤r worker startar fÃ¶rsta gÃ¥ngen:
1. âœ… Ollama startar
2. âœ… Pullar basmodell `mistral-nemo:12b-instruct-2407-q4_K_M` (~7GB, 5-10 min)
3. âœ… Skapar `nocturne-swe` frÃ¥n Modelfile (~30 sek)

**Total tid fÃ¶rsta gÃ¥ngen: 10-15 minuter.**

---

## Steg 5: Verifiera i Logs

### 5.1 GÃ¥ till Logs

1. **RunPod Dashboard â†’ Din Endpoint**
2. **Klicka "Logs" tab**

### 5.2 Leta Efter

Du bÃ¶r se:
```
[RunPod] Checking if model nocturne-swe exists...
[RunPod] Model nocturne-swe not found, creating from Modelfile...
[RunPod] Pulling base model: mistral-nemo:12b-instruct-2407-q4_K_M
[RunPod] Base model pulled successfully
[RunPod] Creating nocturne-swe from Modelfile...
[RunPod] Model nocturne-swe created successfully
[RunPod] Model nocturne-swe is ready
```

### 5.3 Om Du Ser Fel

**"Model not found":** Modellen skapas fortfarande, vÃ¤nta lite till.

**"Modelfile not found":** Kontrollera att Modelfile Ã¤r pushad till GitHub.

**"Failed to pull base model":** NÃ¤tverksproblem, fÃ¶rsÃ¶k igen senare.

---

## Steg 6: Testa frÃ¥n Din Server

### 6.1 Uppdatera `.env`

Ã–ppna `gpt-relay-server/.env`:

```bash
USE_RUNPOD=true
RUNPOD_ENDPOINT_URL=https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/run
RUNPOD_API_KEY=your_api_key_here
OLLAMA_MODEL=nocturne-swe
```

### 6.2 Starta Server

```bash
cd gpt-relay-server
node server.js
```

### 6.3 Testa

GÃ¥ till: `http://localhost:3000/test-chat.html`

Klicka "Generate" och vÃ¤nta pÃ¥ svar.

---

## Steg 7: FelsÃ¶kning

### Problem: "Model not found"

**LÃ¶sning:** VÃ¤nta lÃ¤ngre. FÃ¶rsta kÃ¶rningen tar 10-15 minuter.

### Problem: "Build failed"

**LÃ¶sning:** 
1. Kolla RunPod logs fÃ¶r felmeddelande
2. Verifiera att alla filer Ã¤r pushade till GitHub
3. Kontrollera Dockerfile syntax

### Problem: "Empty response"

**LÃ¶sning:**
1. Kolla RunPod logs
2. Verifiera att modellen Ã¤r skapad
3. Testa med en enklare prompt fÃ¶rst

---

## âœ… Checklista

- [ ] Kod fungerar lokalt
- [ ] Alla filer pushade till GitHub
- [ ] Endpoint skapad frÃ¥n GitHub repo
- [ ] Environment variables konfigurerade
- [ ] VÃ¤ntat pÃ¥ build (2-5 min)
- [ ] VÃ¤ntat pÃ¥ fÃ¶rsta kÃ¶rning (10-15 min)
- [ ] Verifierat i logs att modellen skapas
- [ ] `.env` uppdaterad med RunPod credentials
- [ ] Testat frÃ¥n lokal server
- [ ] Det fungerar! ðŸŽ‰

---

## ðŸŽ¯ Snabb Start

**Om du vill gÃ¥ snabbt:**

1. **Pusha till GitHub:**
   ```bash
   cd gpt-relay-server
   git add .
   git commit -m "Deploy"
   git push
   ```

2. **Skapa Endpoint:**
   - RunPod Dashboard â†’ New Endpoint
   - Import Git Repository â†’ `asdqwe222-d/nocturne-reply`
   - Konfigurera som ovan
   - Skapa

3. **VÃ¤nta 15 minuter** (fÃ¶rsta gÃ¥ngen)

4. **Testa!**

---

**LÃ¥t oss bÃ¶rja om frÃ¥n bÃ¶rjan med denna guide!** ðŸš€

