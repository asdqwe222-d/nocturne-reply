# üéØ Anv√§nd RunPod Template ist√§llet

## Problem

Ollama-installation i Dockerfile orsakar problem. L√•t oss anv√§nda RunPod templates eller exempel-repos ist√§llet!

---

## Option 1: RunPod Hub - Ollama Templates (Rekommenderat)

RunPod har ett **Hub** med f√∂rkonfigurerade templates: https://docs.runpod.io/hub

### Steg 1: S√∂k efter Ollama Template

1. **G√• till RunPod Dashboard**
2. **Klicka "Serverless" ‚Üí "New Endpoint"**
3. **V√§lj "Templates" tab** (eller "Hub")
4. **S√∂k efter "Ollama"**
5. **V√§lj ett Ollama template** (t.ex. "Ollama Serverless")

### Steg 2: Konfigurera Template

**Basic Settings:**
- Endpoint Name: `nocturne-ollama`
- GPU Type: A40 eller RTX 3090
- Worker Type: Flex

**Template Settings:**
- Model: `nocturne-swe` (eller din modell)
- Environment Variables:
  ```
  OLLAMA_MODEL=nocturne-swe
  OLLAMA_HOST=0.0.0.0:11434
  ```

### Steg 3: Anpassa f√∂r din handler.py

Efter att endpoint √§r skapad:
- Template har redan Ollama installerat och konfigurerat
- Du kan anropa Ollama direkt via API
- Eller l√§gg till din handler.py senare via GitHub integration

---

## Option 2: Anv√§nd Ollama Docker Image direkt

Ist√§llet f√∂r att installera Ollama, anv√§nd Ollamas officiella Docker image:

### Uppdatera Dockerfile:

```dockerfile
FROM ollama/ollama:latest

# Install Python och dependencies
RUN apt-get update && apt-get install -y python3 python3-pip && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY handler.py /app/handler.py
COPY requirements.txt /app/requirements.txt

RUN pip3 install --no-cache-dir runpod requests

ENV OLLAMA_MODEL=nocturne-swe
ENV OLLAMA_HOST=0.0.0.0:11434

# Start Ollama i bakgrunden och sedan handler
CMD ollama serve & sleep 5 && python3 /app/handler.py
```

**F√∂rdelar:**
- ‚úÖ Ollama √§r redan installerat och konfigurerat
- ‚úÖ Mindre risk f√∂r installation-problem
- ‚úÖ Officiell image = mer stabil

---

## Option 3: Anv√§nd RunPod Ollama Base Image (Om den finns)

Kolla om RunPod har en officiell Ollama base image:

```dockerfile
FROM runpod/ollama:latest

WORKDIR /app
COPY handler.py /app/handler.py
COPY requirements.txt /app/requirements.txt

RUN pip install --no-cache-dir runpod requests

ENV OLLAMA_MODEL=nocturne-swe
ENV OLLAMA_HOST=0.0.0.0:11434

CMD ["python", "/app/handler.py"]
```

**Kolla om denna image finns:**
- RunPod kan ha en officiell Ollama image
- Eller s√∂k i RunPod Hub efter "ollama"

---

## Option 4: Fork RunPod Ollama Exempel Repo

RunPod kan ha exempel-repos p√• GitHub:

1. **S√∂k p√• GitHub:**
   - `runpod/ollama-serverless`
   - `runpod/serverless-templates`
   - `runpod/ollama-example`
   - `runpodio/serverless-handlers`

2. **Fork repo:**
   - Klicka "Fork" p√• GitHub
   - L√§gg till din handler.py
   - Push till ditt fork

3. **Anv√§nd i RunPod:**
   - Skapa endpoint fr√•n ditt fork
   - Konfigurera som vanligt

---

## Rekommendation

**B√∂rja med Option 2 (Ollama Docker Image)** - det √§r enklast och mest testat!

Om det inte fungerar:
- Prova Option 1 (RunPod Template fr√•n Hub)
- Eller Option 4 (Fork exempel-repo)

---

## N√§sta Steg

Vilken option vill du prova?

1. **Option 2** - Uppdatera Dockerfile med `ollama/ollama:latest` ‚≠ê (Rekommenderat)
2. **Option 1** - Anv√§nd RunPod Template fr√•n Hub
3. **Option 4** - Fork RunPod exempel-repo

---

**Vill du att jag uppdaterar Dockerfile med Option 2?** üöÄ

