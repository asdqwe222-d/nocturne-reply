# ðŸ”§ KÃ¶ra Anpassad Modell med RunPod Hub Template

## Problem

Du anvÃ¤nder **RunPod Hub template** (`SvenBrnn/runpod-worker-ollama`), vilket betyder:
- âŒ Du kan inte Ã¤ndra Dockerfile direkt
- âŒ Du kan inte Ã¤ndra handler.py direkt
- âŒ Template fÃ¶rvÃ¤ntar sig att modellen redan finns i Ollama's registry
- âŒ `nocturne-swe` finns inte i Ollama's registry (det Ã¤r en anpassad modell)

---

## âœ… LÃ¶sning 1: AnvÃ¤nd Standardmodell (Enklast)

**AnvÃ¤nd en modell som finns i Ollama's registry:**

### Steg 1: Ã„ndra Environment Variable

I RunPod Dashboard â†’ Edit Endpoint â†’ Environment Variables:

```
OLLAMA_MODEL_NAME=llama3
```

Eller:
```
OLLAMA_MODEL_NAME=mistral
```

### Steg 2: Uppdatera Lokal `.env`

```bash
OLLAMA_MODEL=llama3
```

### Steg 3: Testa

Detta fungerar direkt eftersom modellen finns i Ollama's registry.

**Nackdel:** Du fÃ¥r inte din anpassade `nocturne-swe` modell med system prompts.

---

## âœ… LÃ¶sning 2: Skapa Modellen via Start Command (Avancerat)

RunPod templates har ofta en "Start Command" dÃ¤r du kan kÃ¶ra scripts.

### Steg 1: Skapa ett Startup Script

Skapa en fil `create-model.sh`:

```bash
#!/bin/bash
# Pull base model
ollama pull mistral-nemo:12b-instruct-2407-q4_K_M

# Create custom model from Modelfile
cat > /tmp/Modelfile << 'EOF'
FROM mistral-nemo:12b-instruct-2407-q4_K_M

PARAMETER temperature 0.8
PARAMETER top_p 0.9
PARAMETER repeat_penalty 1.3
PARAMETER num_ctx 8192

SYSTEM """
You are a flirty, confident Swedish woman texting...
[Resten av din Modelfile]
"""
EOF

ollama create nocturne-swe -f /tmp/Modelfile
```

### Steg 2: LÃ¤gg till Start Command i RunPod

I RunPod Dashboard â†’ Edit Endpoint â†’ Docker Configuration â†’ Start Command:

```bash
sh -c "ollama pull mistral-nemo:12b-instruct-2407-q4_K_M && ollama create nocturne-swe -f <(cat << 'EOF'
FROM mistral-nemo:12b-instruct-2407-q4_K_M
PARAMETER temperature 0.8
PARAMETER top_p 0.9
PARAMETER repeat_penalty 1.3
PARAMETER num_ctx 8192
SYSTEM \"\"\"
You are a flirty, confident Swedish woman texting...
\"\"\"
EOF
) && [original start command]"
```

**Problem:** Detta Ã¤r komplicerat och kan vara svÃ¥rt att fÃ¥ rÃ¤tt.

---

## âœ… LÃ¶sning 3: Bygg Egen Docker Image (BÃ¤st fÃ¶r Anpassad Modell)

### Steg 1: Bygg Docker Image Lokalt eller via GitHub Actions

AnvÃ¤nd din egen Dockerfile som skapar modellen automatiskt.

### Steg 2: Push till RunPod Registry

```bash
# Login till RunPod Registry
docker login registry.runpod.net -u <your-runpod-username> -p <your-runpod-api-key>

# Tag image
docker tag your-image:latest registry.runpod.net/your-username/your-image:latest

# Push
docker push registry.runpod.net/your-username/your-image:latest
```

### Steg 3: AnvÃ¤nd Din Image i RunPod

I RunPod Dashboard â†’ Edit Endpoint â†’ Docker Configuration â†’ Container Image:

```
registry.runpod.net/your-username/your-image:latest
```

**FÃ¶rdel:** Full kontroll Ã¶ver modellskapande
**Nackdel:** KrÃ¤ver Docker och RunPod Registry access

---

## âœ… LÃ¶sning 4: AnvÃ¤nd Network Volume (Persistent Storage)

### Steg 1: Skapa Network Volume i RunPod

RunPod Dashboard â†’ Storage â†’ Create Volume

### Steg 2: Ladda Upp Modelfile till Volymen

Via RunPod Pod eller direkt upload.

### Steg 3: Mounta Volymen i Endpoint

I Edit Endpoint â†’ Advanced â†’ Network Volume â†’ VÃ¤lj din volume

### Steg 4: Skapa Modellen vid Startup

Via Start Command eller environment variable script.

**FÃ¶rdel:** Modellen sparas mellan restarts
**Nackdel:** KrÃ¤ver extra konfiguration

---

## ðŸŽ¯ Rekommendation

**FÃ¶r nu:** AnvÃ¤nd **LÃ¶sning 1** (standardmodell) fÃ¶r att fÃ¥ det att fungera snabbt.

**Senare:** Implementera **LÃ¶sning 3** (egen Docker image) fÃ¶r din anpassade modell.

---

## ðŸš€ Snabb Fix Nu

1. **GÃ¥ till RunPod Dashboard â†’ Edit Endpoint**
2. **Environment Variables â†’ Ã„ndra:**
   ```
   OLLAMA_MODEL_NAME=llama3
   ```
3. **Spara**
4. **Testa**

Detta fungerar direkt! ðŸŽ‰

