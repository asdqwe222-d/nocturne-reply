# ‚ö° Snabb Test - RunPod Endpoint

## Problem: Logs √§r tomma, kan inte testa fr√•n Dashboard

**L√∂sning:** Testa fr√•n din egen server ist√§llet!

---

## Steg 1: Verifiera .env

√ñppna `gpt-relay-server/.env` och kontrollera:

```bash
RUNPOD_ENDPOINT_URL=https://api.runpod.ai/v2/kjuxscfof20t8h/run
RUNPOD_API_KEY=din-api-key-h√§r
USE_RUNPOD=true
OLLAMA_MODEL=nocturne-swe
```

**VIKTIGT:** Om `nocturne-swe` inte finns i RunPod, √§ndra till:

```bash
OLLAMA_MODEL=llama3
```

---

## Steg 2: Starta Servern

```bash
cd gpt-relay-server
node server.js
```

Du b√∂r se:
```
üåê RunPod Serverless: ENABLED
   Endpoint: https://api.runpod.ai/v2/kjuxscfof20t8h/run...
```

---

## Steg 3: Testa Generation

1. √ñppna: `http://localhost:3000/test-chat.html`
2. Skriv ett meddelande
3. Klicka "Generate"

---

## Steg 4: Kolla Terminal Logs

**Om det fungerar:**
```
[Nocturne] Calling RunPod Serverless...
[RunPod] Calling serverless endpoint: https://api.runpod.ai/v2/...
[RunPod] Full response: {...}
[RunPod] Response received, length: XXX
```

**Om det misslyckas:**
```
[RunPod] API error: 500
[RunPod] Error details: {...}
```

**Kopiera dessa logs och skicka hit!**

---

## Om Modellen Inte Finns

Om du ser `Model not found`:

1. √Ñndra i `.env`: `OLLAMA_MODEL=llama3`
2. Starta om servern
3. Testa igen

---

## N√§sta Steg

1. ‚úÖ Starta servern
2. ‚úÖ Testa generation
3. ‚úÖ Kopiera logs fr√•n terminalen
4. ‚úÖ Skicka logs hit s√• kan jag hj√§lpa dig fixa!

